{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f92b54a4",
      "metadata": {
        "id": "f92b54a4"
      },
      "source": [
        "# LangChain Basics\n",
        "\n",
        "LangChain is a framework designed to simplify the development of applications involving large language models (LLMs). LangChain allows you to build powerful, context-aware applications by leveraging its tools for chaining LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85351958",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T14:22:37.625504Z",
          "start_time": "2024-06-06T14:22:23.455271Z"
        },
        "collapsed": true,
        "id": "85351958"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain==0.2.2\n",
        "!pip install -q langchain_community==0.2.3\n",
        "!pip install -q langchain-openai==0.1.8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3a07280",
      "metadata": {
        "id": "f3a07280"
      },
      "source": [
        "## Prerequisite: Generate OpenAI key\n",
        "\n",
        "Generate key from: https://platform.openai.com/api-keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282b2550",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T14:26:32.557670Z",
          "start_time": "2024-06-06T14:26:32.555816Z"
        },
        "id": "282b2550"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c2917f",
      "metadata": {
        "id": "a0c2917f"
      },
      "source": [
        "## Call OpenAI using Langchain Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49d7813b",
      "metadata": {
        "id": "49d7813b"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "messages = [\n",
        "    HumanMessage(content=\"Hello!\")\n",
        "]\n",
        "m = model.invoke(messages)\n",
        "# m.content: message from LLM\n",
        "\n",
        "parser = StrOutputParser()\n",
        "parser.invoke(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e373f1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T14:29:31.667470Z",
          "start_time": "2024-06-06T14:29:31.665545Z"
        },
        "id": "21e373f1"
      },
      "outputs": [],
      "source": [
        "chain = model | parser # write process as chain\n",
        "chain.invoke(messages) # same result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cb158b2",
      "metadata": {
        "id": "9cb158b2"
      },
      "source": [
        "## Building Improve Grammar App using Langchain PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e7df91d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T14:40:09.436696Z",
          "start_time": "2024-06-06T14:40:09.434885Z"
        },
        "id": "0e7df91d"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
        "style_prompts = {\n",
        "    \"default\": \"\",\n",
        "    \"academic\": \"Ensure that the language used is appropriate for an academic research publication.\",\n",
        "    \"ielts\": \"Using fancy words. Ensure that the language used meets the standards required for an IELTS score of 8.0.\",\n",
        "    \"informal\": \"Make it informal like talking to a friend.\"\n",
        "}\n",
        "\n",
        "user_text = \"Hello again mine frinnds!\"\n",
        "user_style = \"ielts\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d90216a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T14:40:10.376203Z",
          "start_time": "2024-06-06T14:40:10.374261Z"
        },
        "id": "0d90216a"
      },
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_template + \" {style}\"),\n",
        "        (\"user\", \"{text}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt_template | model | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4cf4d74",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T14:43:24.478728Z",
          "start_time": "2024-06-06T14:43:24.475882Z"
        },
        "id": "b4cf4d74"
      },
      "outputs": [],
      "source": [
        "def improve_grammar(text, style=\"default\"):\n",
        "    style_text = style_prompts[style]\n",
        "\n",
        "    return chain.invoke({\"text\": text, \"style\": style_text})\n",
        "\n",
        "improve_grammar(user_text, user_style)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "163fed31",
      "metadata": {
        "id": "163fed31"
      },
      "source": [
        "## Including Chat History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87783997",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T17:48:24.241343Z",
          "start_time": "2024-06-06T17:48:23.353076Z"
        },
        "id": "87783997"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "messages = [\n",
        "    # include history\n",
        "    HumanMessage(content=\"Hello my name is Oat!\"),\n",
        "    AIMessage(content=\"Hello Oat, nice to meet you! How can I assist you today?\"),\n",
        "    HumanMessage(content=\"What's my name?\")\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a269b0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T17:51:24.696561Z",
          "start_time": "2024-06-06T17:51:24.681459Z"
        },
        "id": "68a269b0"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(model, get_session_history) # wrap model object\n",
        "config = {\"configurable\": {\"session_id\": \"chat-01\"}} # config session id\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"Hi! I'm Oat!\")\n",
        "    ],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print(store)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645bd8e1",
      "metadata": {
        "id": "645bd8e1"
      },
      "source": [
        "## Personalize Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae483f5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T18:01:04.163878Z",
          "start_time": "2024-06-06T18:01:04.161337Z"
        },
        "id": "5ae483f5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant named \\\"Arise\\\"\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt_template | model\n",
        "config = {\"configurable\": {\"session_id\": \"chat-01\"}}\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Oat!\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a33be7a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-06T18:01:13.297845Z",
          "start_time": "2024-06-06T18:01:12.417983Z"
        },
        "id": "3a33be7a"
      },
      "outputs": [],
      "source": [
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's your name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print(response.content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}